{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192b08a8",
   "metadata": {},
   "source": [
    "Processamento dei dati json scaricati in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90356f8-7c49-48ab-8aea-064eaeef0f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstorage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mblob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BlobServiceClient\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m execute_values\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def safe_int(value):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def safe_fromtimestamp(ts):\n",
    "    try:\n",
    "        # Assicurati che ts sia int e positivo (Unix epoch)\n",
    "        if ts is None or ts <= 0:\n",
    "            return None\n",
    "        return datetime.datetime.fromtimestamp(int(ts)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825b748d-fc4c-42a3-9113-992519599ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"localhost\" (::1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(os.getenv(\u001b[33m\"\u001b[39m\u001b[33mPOSTGRES_HOST\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# PostgreSQL connection\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m conn = \u001b[43mpsycopg2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOSTGRES_HOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOSTGRES_PORT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOSTGRES_USER\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOSTGRES_PASSWORD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOSTGRES_DB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Azure Blob Storage connection\u001b[39;00m\n\u001b[32m     13\u001b[39m connection_string = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mBLOBSTORAGE_CONNECTIONSTRING\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Data Science\\trains\\Lib\\site-packages\\psycopg2\\__init__.py:135\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    132\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    134\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    137\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mOperationalError\u001b[39m: connection to server at \"localhost\" (::1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)\n\tIs the server running on that host and accepting TCP/IP connections?\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"POSTGRES_HOST\"))\n",
    "\n",
    "# PostgreSQL connection\n",
    "conn = psycopg2.connect(\n",
    "    host = os.getenv(\"POSTGRES_HOST\"),\n",
    "    port = os.getenv(\"POSTGRES_PORT\"),\n",
    "    dbname = os.getenv(\"POSTGRES_USER\"),\n",
    "    user = os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    password = os.getenv(\"POSTGRES_DB\")\n",
    ")\n",
    "\n",
    "# Azure Blob Storage connection\n",
    "connection_string = os.getenv(\"BLOBSTORAGE_CONNECTIONSTRING\")\n",
    "container_name = os.getenv(\"BLOBSTORAGE_CONTAINERNAME\")\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378bc6e9-6c2d-4294-86de-dff0c568283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DELETE FROM railway.timetable\")\n",
    "conn.commit()\n",
    "logging.info(\"Deleted all records from railway.timetable\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DELETE FROM railway.train\")\n",
    "conn.commit()\n",
    "logging.info(\"Deleted all records from railway.train\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DELETE FROM railway.station\")\n",
    "conn.commit()\n",
    "logging.info(\"Deleted all records from railway.station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde1f4d-1d5c-456b-8479-c5b907d140d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psycopg2\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# === Inizializza geolocalizzatore ===\n",
    "geolocator = Nominatim(user_agent=\"station_mapper\")\n",
    "\n",
    "def get_city_region(station_name):\n",
    "    \"\"\"Deduci cittÃ  e regione da nome stazione tramite Nominatim.\"\"\"\n",
    "    try:\n",
    "        location = geolocator.geocode(f\"{station_name}, Italy\", timeout=10)\n",
    "        if location:\n",
    "            address = geolocator.reverse((location.latitude, location.longitude), language=\"it\").raw.get('address', {})\n",
    "            city = address.get('city') or address.get('town') or address.get('village') or ''\n",
    "            region = address.get('state', '')\n",
    "            return city, region\n",
    "    except Exception as e:\n",
    "        print(f\"Geocoding error for '{station_name}': {e}\")\n",
    "    return '', ''\n",
    "\n",
    "# === Connessione DB ===\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    user=\"uniud\",\n",
    "    password=\"AndSpo166930!!\",\n",
    "    host=\"datascienceuniud.postgres.database.azure.com\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# === Estrai stazioni incomplete ===\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT id, name FROM railway.station\n",
    "    WHERE (city IS NULL OR city = '')\n",
    "      AND (region IS NULL OR region = '');\n",
    "\"\"\")\n",
    "stations_to_update = cursor.fetchall()\n",
    "\n",
    "print(f\"Found {len(stations_to_update)} station(s) to update.\\n\")\n",
    "\n",
    "# === Aggiorna ciascuna stazione ===\n",
    "for station_id, name in stations_to_update:\n",
    "    print(f\"Looking up: {name}\")\n",
    "    city, region = get_city_region(name)\n",
    "\n",
    "    if city or region:\n",
    "        cursor.execute(\"\"\"\n",
    "            UPDATE railway.station\n",
    "            SET city = %s, region = %s\n",
    "            WHERE id = %s;\n",
    "        \"\"\", (city, region, station_id))\n",
    "        conn.commit()\n",
    "        print(f\"Updated station ID {station_id} with city='{city}', region='{region}'\")\n",
    "    else:\n",
    "        print(f\"Could not find location info for '{name}'\")\n",
    "\n",
    "    time.sleep(1)  # Rispetta rate limit Nominatim\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nAll done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9984a9-58b3-4b73-9c19-cb3977140350",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobName_list = container_client.list_blob_names()\n",
    "\n",
    "for i, blobName in enumerate(blobName_list):\n",
    "\n",
    "    # === Extract unique station names and train info ===\n",
    "    stations = {}\n",
    "    trains = {}\n",
    "    timetable = []\n",
    "    \n",
    "    print(f\"Processing blob: {blobName}\")\n",
    "    blobClient = blob_service_client.get_blob_client(container=container_name, blob=blobName)\n",
    "    blobBytes = blobClient.download_blob().readall()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(blobBytes)\n",
    "        trainsJson = data.get(\"treni\", [])\n",
    "        \n",
    "\n",
    "        for train in trainsJson:\n",
    "            trainNumber = train.get(\"n\")\n",
    "            trainType = train.get(\"c\")\n",
    "            cancellationMessage = train.get(\"dl\")\n",
    "\n",
    "            if trainNumber and trainNumber not in trains:\n",
    "                trains[trainNumber] = {\n",
    "                    \"id\": trainNumber,\n",
    "                    \"type\": trainType\n",
    "                }\n",
    "\n",
    "            for s, stop in enumerate(train.get(\"fr\", [])):\n",
    "                name = stop.get(\"n\")\n",
    "                if name and name not in stations:\n",
    "                    stations[name] = {\n",
    "                        \"name\": name,\n",
    "                        \"city\": \"\",\n",
    "                        \"region\": \"\"\n",
    "                    }\n",
    "\n",
    "                arrival_delay = None if stop.get(\"ra\") in [\"N\", \"S\", \"n.d.\"] else safe_int(stop.get(\"ra\"))\n",
    "                departure_delay = None if stop.get(\"rp\") in [\"N\", \"S\", \"n.d.\"] else safe_int(stop.get(\"rp\"))\n",
    "                arrival_time = None if stop.get(\"oa\") in [0, \"0\", \"n.d.\"] else safe_int(stop.get(\"oa\"))\n",
    "                departure_time = None if stop.get(\"op\") in [0, \"0\", \"n.d.\"] else safe_int(stop.get(\"op\"))\n",
    "                deleted = True if (stop.get(\"op\") == 0 and cancellationMessage) else False\n",
    "\n",
    "                timetable.append({\n",
    "                    \"train_id\": trainNumber,\n",
    "                    \"stop_number\": s,\n",
    "                    \"day_number\": i,\n",
    "                    \"station_name\": name,\n",
    "                    \"arrival_datetime\": safe_fromtimestamp(arrival_time),\n",
    "                    \"departure_datetime\": safe_fromtimestamp(departure_time),\n",
    "                    \"arrival_delay\": arrival_delay,\n",
    "                    \"departure_delay\": departure_delay,\n",
    "                    \"deleted\": deleted\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing file {blobName}: {e}\")\n",
    "\n",
    "    # === Insert new stations only ===\n",
    "    print(f\"Stations to insert: {len(stations)}\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    insert_station_sql = \"\"\"\n",
    "    INSERT INTO railway.station (name, city, region)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (name) DO NOTHING;\n",
    "    \"\"\"\n",
    "\n",
    "    station_to_insert = [(s['name'], s['city'], s['region']) for s in stations.values()]\n",
    "\n",
    "    execute_values(cursor, insert_station_sql, station_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Stations commited\")\n",
    "\n",
    "    # === Insert new trains only ===\n",
    "    print(f\"Trains to insert: {len(trains)}\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    insert_train_sql = \"\"\"\n",
    "    INSERT INTO railway.train (id, type)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (id) DO NOTHING;\n",
    "    \"\"\"\n",
    "\n",
    "    train_to_insert = [(t['id'], t['type']) for t in trains.values()]\n",
    "\n",
    "    execute_values(cursor, insert_train_sql, train_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Trains commited\")\n",
    "\n",
    "    # === Recupera mapping nome -> id stazione dal DB ===\n",
    "    cursor.execute(\"SELECT id, name FROM railway.station\")\n",
    "    station_rows = cursor.fetchall()\n",
    "    station_name_to_id = {name: sid for sid, name in station_rows}\n",
    "\n",
    "    # === Costruisci i dati da inserire nella tabella timetable ===\n",
    "    timetable_to_insert = []\n",
    "\n",
    "    for row in timetable:\n",
    "        station_id = station_name_to_id.get(row[\"station_name\"])\n",
    "        if not station_id:\n",
    "            continue\n",
    "\n",
    "        timetable_to_insert.append((\n",
    "            station_id,\n",
    "            row[\"train_id\"],\n",
    "            row[\"stop_number\"],\n",
    "            row[\"day_number\"],\n",
    "            row[\"arrival_datetime\"],\n",
    "            row[\"departure_datetime\"],\n",
    "            row[\"arrival_delay\"],\n",
    "            row[\"departure_delay\"],\n",
    "            row[\"deleted\"]\n",
    "        ))\n",
    "\n",
    "    # === Inserisci nella tabella railway.timetable ===\n",
    "    print(f\"Timetable records to insert: {len(timetable_to_insert)}\")\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    insert_timetable_sql = \"\"\"\n",
    "    INSERT INTO railway.timetable (\n",
    "        station_id,\n",
    "        train_id,\n",
    "        stop_number,\n",
    "        day_number,\n",
    "        arrival_datetime,\n",
    "        departure_datetime,\n",
    "        arrival_delay,\n",
    "        departure_delay,\n",
    "        deleted\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT DO NOTHING;\n",
    "    \"\"\"\n",
    "\n",
    "    execute_values(cursor, insert_timetable_sql, timetable_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Timetable commited\")\n",
    "\n",
    "    cursor.close()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad797981-4c02-4e86-b096-4f32611e3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from io import BytesIO\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# === Azure Blob Storage connection ===\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=spolaorandreapersonal;AccountKey=2PYZixgZHGr9yNowk+nZ6d2XfGqwpuR/Gd4XYxw50gSLfckTD9xMl5ExkHUyZ7OmzahrvD7bQ2wE+AStlxVKCQ==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"datascience\"\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "blobName_list = container_client.list_blob_names()\n",
    "\n",
    "# === PostgreSQL connection ===\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    user=\"uniud\",\n",
    "    password=\"AndSpo166930!!\",\n",
    "    host=\"datascienceuniud.postgres.database.azure.com\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# === Extract unique station names ===\n",
    "stations = {}\n",
    "\n",
    "for i, blobName in enumerate(blobName_list):\n",
    "    if i >= 1:\n",
    "        break\n",
    "        \n",
    "    print(f\"Processing blob: {blobName}\")\n",
    "    blobClient = blob_service_client.get_blob_client(container=container_name, blob=blobName)\n",
    "    blobBytes = blobClient.download_blob().readall()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(blobBytes)\n",
    "        trainNumber = data.get(\"n\")\n",
    "        trains = data.get(\"treni\", [])\n",
    "        for train in trains:\n",
    "            for stop in train.get(\"fr\", []):\n",
    "                name = stop.get(\"n\")\n",
    "                arrivalTime = stop.get(\"oa\")\n",
    "                departureTime = stop.get(\"op\")\n",
    "                arrivalDelay = if stop.get(\"ra\")\n",
    "                departureDelay = stop.get(\"rp\")\n",
    "\n",
    "                # === Insert new stations only ===\n",
    "                insert_query = \"\"\"\n",
    "                INSERT INTO railway.station (name, city, region)\n",
    "                VALUES ({}, {}, {}, {})\n",
    "                ON CONFLICT (name) DO NOTHING;\n",
    "                \"\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing file {blobName}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "execute_values(cursor, insert_query, records_to_insert)\n",
    "conn.commit()\n",
    "\n",
    "print(f\"{cursor.rowcount} new station(s) inserted. Existing ones were skipped.\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
